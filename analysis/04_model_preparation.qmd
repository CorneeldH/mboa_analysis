---
title: "Model Data Preparation"
author: "MBOA Analysis Team"
date: last-modified
---

```{r}
#| label: setup
#| cache: false
#| output: false
#| include: false
#| freeze: false

source("utils/dev_functions.R")
source("utils/manage_packages.R")

# Load all functions from the R package
load_all()

```

## Introductie

Dit document bereidt gegevens voor ten behoeve van voorspellende modellering van studentuitval over verschillende onderwijsprogramma's en niveaus. Het voorbereidingsproces omvat:

1. Laden van de benodigde datasets
2. Filteren en voorverwerken van gegevens
3. Opsplitsen van gegevens in trainings- en testsets
4. Opslaan van voorbereide gegevens in een georganiseerde structuur

## Gegevens laden

Als eerste laden we de gecombineerde en verrijkte inschrijvingsgegevens uit onze datapijplijn. Dit zijn dus gegevens op studentinschrijving niveau, voordat deze zijn geaggregeerd en gefilterd voor het correlatie-onderzoek op teamniveau in een eerder stadium.

```{r}
#| label: load-data

# Load the data
enrollments_raw <- readRDS(file.path(config::get("data_combined_dir"),
                                     "enrollments_combined_enriched.rds"))

# Create shortened names for teams and programs
enrollments_with_short_names <- enrollments_raw %>%
  mutate(
    TEAM_naam_kort = case_when(
      str_detect(TEAM_naam, "Beveiliging/Toezicht en Veiligheid") ~ "Beveiliging",
      str_detect(TEAM_naam, "Kappersschool Amersfoort") ~ "Kapperschool",
      str_detect(TEAM_naam, "Commercie en Evenementen") ~ "Commercie/Events",
      str_detect(TEAM_naam, "Hotelschool Amersfoort") ~ "Hotelschool",
      str_detect(TEAM_naam, "School voor Schoonheidsspecialisten") ~ "Schoonheid spec.",
      str_detect(TEAM_naam, "School voor Toerisme & Management") ~ "Toerisme & Mgt",
      str_detect(TEAM_naam, "Sportacademie Amersfoort") ~ "Sportacademie",
      str_detect(TEAM_naam, "FinanciÃ«le Beroepen") ~ "Fin. Beroepen",
      str_detect(TEAM_naam, "MEI") ~ "MEI (Techniek)",
      .default = TEAM_naam
    ),
    OPLEIDING_crebo = as.numeric(gsub("[^0-9]", "", OPLEIDING_code)),
    # Handle potential NA values in creating shortened names
    OPLEIDING_naam_kort = case_when(
      is.na(OPLEIDING_naam) ~ "Onbekend",
      is.na(OPLEIDING_crebo) ~ word(OPLEIDING_naam, 1),
      TRUE ~ paste0(word(OPLEIDING_naam, 1), " (", OPLEIDING_crebo, ")")
    ),
    OPLEIDING_bc_label_kort = case_when(
      is.na(OPLEIDING_bc_label) ~ "Onbekend",
      is.na(OPLEIDING_bc_code) ~ word(OPLEIDING_bc_label, 3),
      TRUE ~ paste0(word(OPLEIDING_bc_label, 3), " (", OPLEIDING_bc_code, ")")
    )
  )

# Function to categorize reasons for leaving
categorize_reasons <- function(reason) {
  case_when(
      # Persoonlijk, of tenminste niet instelling-gerelateerd (Personal reasons)
      reason %in% c(
          "Verhuizing/reistijd",
          "Financi\xeble situatie",
          "Niet verschenen",
          "Verwijderd",
          "Detentie"
      ) ~ "Persoonsgebonden buiten invloed MBOA",
      
      reason %in% c(
          "Persoonlijk functioneren",
          "Persoonlijke omstandigheden",
          "Leerproblemen/onvoldoende capaciteit",
          "Onvoldoende taal/rekenen"
          
      ) ~ "Persoonsgebonden binnen invloed MBOA",
      
      # Werk (Work-related)
      reason %in% c(
          "Geen (erkend) leerbedrijf",
          "Ontslag of POK be\xebindigd",
          "Liever (fulltime) werken",
          "Werk of stage past niet",
          "Heeft arbeidsovereenkomst"
      ) ~ "Arbeidsmarkt",
      
      # Organisatie (Organizational)
      reason %in% c(
          "Schoolorganisatie",
          "Sociale/fysieke veiligheid",
          "Huisvesting/voorzieningen",
          "Onderwijs/didactiek",
          "Onvoldoende begeleiding"
      ) ~ "Instellingsgeboden",
      
      # Marketing (Expectations vs reality)
      reason %in% c(
          "Belangstelling andere opleiding/beroep",
          "Verkeerd beroepsbeeld",
          "Verkeerd opleidingsbeeld"
      ) ~ "Studie en beroepskeuze",
      
      reason %in% c(
          "No Show", 
          "Ambtshalve"
      ) ~ "Ambsthalve & No Show",
      
      reason %in% c(
          "Keuzedeel toevoegen",
          "DOORstroom: Organisatorisch",
          "DOORstroom: Examenstudent",
          "DOORstroom: Profiel => Uitstroomcrebo",
          "DOORstroom:Verlenger/Vertrager"
      ) ~ "Administratief",
      
      # Succes (Successful completion/progression)
      reason %in% c(
          "Certificaat",
          "Diploma",
          "Tweede diploma (in kalenderjaar)",
          "Zonder diploma, wel succesvol"
      ) ~ "Succes",
      
      is.na(reason) ~ "Nog steeds ingeschreven",
      # Everything else goes to "Overig" (Other)
      #  "Houding medewerkers",
      # "Administratieve  fout"
      #     "Persoonsgebonden",
      # "Besluit Student zie documenten",
      # "Te veel nevenactiviteiten",
      # "Besluit Intake vlg Stamkaart",
      TRUE ~ "Overig"
  )
}
```

```{r}
# Add categorized reasons for leaving
enrollments_with_categories <- enrollments_with_short_names |>
  mutate(
    VERBINTENIS_reden_uitschrijving_categorie = categorize_reasons(VERBINTENIS_reden_uitschrijving)
  )

# Add dropout indicators per student and BC code
enrollments_with_dropout_indicators <- enrollments_with_categories |>
  # Sort by student ID and start date to get chronological order
  arrange(DEELNEMER_ID, VERBINTENIS_begindatum) |>
  # Group by student and BC code
  group_by(DEELNEMER_ID, OPLEIDING_bc_label_kort) |>
  mutate(
    # Basic counts and details
    aantal_inschrijvingen = n(),
    DEELNEMER_BC_begindatum_eerst = min(VERBINTENIS_begindatum, na.rm = TRUE),
    DEELNEMER_BC_einddatum_laatst = if_else(
      is.na(max(VERBINTENIS_einddatum)),
      max(as.Date(VERBINTENIS_geplande_einddatum, format = "%d-%m-%Y")),
      max(VERBINTENIS_einddatum)
    ),
    
    # Total duration in days across all enrollments with this BC code
    DEELNEMER_BC_inschrijvingsduur = as.numeric(difftime(DEELNEMER_BC_einddatum_laatst, 
                                              DEELNEMER_BC_begindatum_eerst, 
                                              units = "days")),
    
    # Latest exit reason
    laatste_uitstroomreden = last(VERBINTENIS_reden_uitschrijving),
    laatste_uitstroomreden_categorie = last(VERBINTENIS_reden_uitschrijving_categorie),
    
    # Success indicators
    DEELNEMER_BC_uitval = !(DEELNEMER_BC_inschrijvingsduur > 365 | laatste_uitstroomreden_categorie == "Succes")
  ) |>
  ungroup()

```

## Variabelen selecteren

```{r}

# Calculate age and select relevant variables for modeling
enrollments_selected <- enrollments_with_dropout_indicators |>
  mutate(DEELNEMER_leeftijd = DEELNEMER_BC_begindatum_eerst - DEELNEMER_geboorte_jaarmaand, 
         DEELNEMER_leeftijd = as.numeric(DEELNEMER_leeftijd, units = "days") / 365.25) |>
     select(DEELNEMER_ID,
           COHORT_startjaar,
           DEELNEMER_leeftijd,
           DEELNEMER_BC_uitval,
           DEELNEMER_geslacht,
           DEELNEMER_BC_begindatum_eerst,
           TEAM_naam_kort,
           AANMELDING_begin_dagen_tot_start,
           AANMELDING_afgerond_dagen_tot_start,
           OPLEIDING_naam_kort,
           OPLEIDING_bc_label_kort,
           DEELNEMER_havo_vwo_is_gezakt,
           VERBINTENIS_niveau,
           AANMELDING_laatst_gewijzigd_datum,
           DEELNEMER_BC_begindatum_eerst,
           DEELNEMER_BC_einddatum_laatst,
           DEELNEMER_BC_inschrijvingsduur,
           DEELNEMER_postcode4_ses_score,
           DEELNEMER_postcode4_ses_spreiding,
           DEELNEMER_postcode4_apcg,
           matches("VERBINTENIS_waarneming_pct_ongeoorloofd_week"),
           matches("VERBINTENIS_waarneming_pct_geoorloofd_week"),
           DEELNEMER_vooropleiding_categorie,
           DEELNEMER_passend_niveau,
           DEELNEMER_plaatsing,
           DEELNEMER_havo_vwo_is_gezakt,
           # TODO Ik heb vraagtekens bij de data kwaliteit van deze variabele
           # start_kwalificatie,
           # Variables to filter on
           VERBINTENIS_intensiteit, 
           VERBINTENIS_bekostigd, 
           OPLEIDING_leerweg,
           VERBINTENIS_begindatum,
           ) |>
    mutate(DEELNEMER_postcode4_apcg = if_else(is.na(DEELNEMER_postcode4_apcg), FALSE, DEELNEMER_postcode4_apcg))
```

## Variabelen filteren

Selecteer alleen studenten die officieel in augustus beginnen, voltijd studeren (BOL) en bekostigd zijn.

```{r}

enrollments_filtered <- enrollments_selected |>
    filter(
        DEELNEMER_BC_begindatum_eerst >= as.Date("2021-08-01", format = "%Y-%m-%d"),
        DEELNEMER_BC_begindatum_eerst <= as.Date("2023-08-31", format = "%Y-%m-%d"),
        # VERBINTENIS_actief_op_1_okt_peildatum == TRUE,
        month(VERBINTENIS_begindatum) == 8,
        month(DEELNEMER_BC_begindatum_eerst) == 8,
        DEELNEMER_BC_begindatum_eerst == VERBINTENIS_begindatum,
        VERBINTENIS_bekostigd == "Ja",
        VERBINTENIS_intensiteit == "Voltijd",
        OPLEIDING_leerweg == "BOL"
    ) |>
    select(-c(VERBINTENIS_intensiteit, VERBINTENIS_bekostigd, OPLEIDING_leerweg))

```

### Aanwezigheid per week filteren
De aanwezigheid variablen beginnen vanaf 1 augustus. Echter, onderwijs begint dan nog niet altijd. We verwijderen daarom de weken zonder onderwijs per opleidingsprogramma en de overgebleven weken om deze bij 1 te laten beginnen.

```{r}
# Function to reorganize week variables by removing all-NA columns and renumbering
reorganize_week_variables <- function(data, group_vars = c("COHORT_startjaar", "OPLEIDING_naam_kort")) {
  # Check if grouping variables exist in the data
  missing_vars <- setdiff(group_vars, names(data))
  if (length(missing_vars) > 0) {
    warning("The following grouping variables are missing from the data: ", 
            paste(missing_vars, collapse = ", "), 
            ". Using available grouping variables only.")
    group_vars <- intersect(group_vars, names(data))
    if (length(group_vars) == 0) {
      message("No valid grouping variables found. Processing the entire dataset as one group.")
    }
  }
  
  # Get the unique groups
  if (length(group_vars) > 0) {
    # Create grouping expression
    groups_list <- data %>%
      group_by(across(all_of(group_vars))) %>%
      group_keys()
  } else {
    # Create a dummy group if no valid grouping variables
    groups_list <- data.frame(dummy_group = "all_data")
    group_vars <- "dummy_group"
  }
  
  # Identify week variables that need processing
  week_vars <- names(data)[grepl("_week_[0-9]+$", names(data))]
  
  # If no week variables found, return original data with a message
  if(length(week_vars) == 0) {
    message("No week variables found in the dataset.")
    return(data)
  }
  
  # Identify the prefix patterns (e.g., "VERBINTENIS_waarneming_pct_ongeoorloofd", "VERBINTENIS_waarneming_pct_geoorloofd")
  prefixes <- unique(gsub("_week_[0-9]+$", "", week_vars))
  
  # Create a list to store group-specific data
  group_data_list <- list()
  
  # Track the weeks removed for each group
  weeks_removed_by_group <- list()
  
  # Initialize an empty data frame to capture all of the renaming that happens
  all_renamings <- data.frame(group = character(), 
                             old_var = character(), 
                             new_var = character(), 
                             stringsAsFactors = FALSE)
  
  # Process each group separately
  for(i in 1:nrow(groups_list)) {
    # Extract group values and create a filter
    if ("dummy_group" %in% names(groups_list)) {
      # Process all data as one group
      group_data <- data
      group_name <- "All data"
    } else {
      # Extract the current group's values
      current_group <- groups_list[i, , drop = FALSE]
      
      # Create filter conditions for each grouping variable
      filter_conditions <- list()
      for (var in group_vars) {
        filter_conditions[[var]] <- current_group[[var]]
      }
      
      # Filter data for the current group
      group_data <- data %>%
        filter(!!!rlang::quos(!!!lapply(seq_along(group_vars), function(j) {
          var <- group_vars[j]
          value <- current_group[[var]]
          rlang::expr(!!rlang::sym(var) == !!value)
        })))
      
      # Create a descriptive name for this group
      group_values <- unlist(current_group)
      group_name <- paste(group_vars, group_values, sep = ": ", collapse = ", ")
    }
    
    # Skip if the group has no data
    if (nrow(group_data) == 0) {
      message("Group [", group_name, "] has no data. Skipping.")
      next
    }
    
    # For this group, track which weeks are removed across all prefixes
    weeks_removed <- c()
    
    # Process each prefix for this group
    for(prefix in prefixes) {
      # Get all variables for this prefix
      prefix_vars <- names(group_data)[grepl(paste0("^", prefix, "_week_[0-9]+$"), names(group_data))]
      
      # Identify which columns are all NA for this group
      na_columns <- prefix_vars[sapply(prefix_vars, function(col) all(is.na(group_data[[col]])))]
      
      # Extract week numbers from NA columns
      if(length(na_columns) > 0) {
        week_nums <- unique(as.numeric(gsub(paste0("^", prefix, "_week_"), "", na_columns)))
        weeks_removed <- unique(c(weeks_removed, week_nums))
      }
      
      # Remove NA columns from group data
      if(length(na_columns) > 0) {
        group_data <- group_data %>% select(-all_of(na_columns))
      }
      
      # Keep only the variables that are not all NA for this prefix
      remaining_vars <- setdiff(prefix_vars, na_columns)
      
      if(length(remaining_vars) > 0) {
        # Extract week numbers from variable names
        week_numbers <- as.numeric(gsub(paste0("^", prefix, "_week_"), "", remaining_vars))
        
        # Create a mapping from old to new week numbers
        old_to_new <- data.frame(
          old_var = remaining_vars,
          old_num = week_numbers,
          new_num = rank(week_numbers),
          stringsAsFactors = FALSE
        ) %>%
          mutate(
            new_var = paste0(prefix, "_week_", sprintf("%02d", new_num))
          )
        
        # If there's any renaming to do (old names differ from new names)
        if(any(old_to_new$old_var != old_to_new$new_var)) {
          # Create a named vector for renaming
          rename_mapping <- setNames(old_to_new$old_var, old_to_new$new_var)
          
          # Capture the renaming for this group
          group_renamings <- data.frame(
            group = rep(group_name, sum(old_to_new$old_var != old_to_new$new_var)),
            old_var = old_to_new$old_var[old_to_new$old_var != old_to_new$new_var],
            new_var = old_to_new$new_var[old_to_new$old_var != old_to_new$new_var],
            stringsAsFactors = FALSE
          )
          all_renamings <- rbind(all_renamings, group_renamings)
          
          # Rename the columns in this group's data
          group_data <- group_data %>%
            rename(!!!rename_mapping)
        }
      }
    }
    
    # Store the weeks that were removed for this group
    if(length(weeks_removed) > 0) {
      weeks_removed_by_group[[group_name]] <- sort(weeks_removed)
    }
    
    # Store the processed group data
    group_data_list[[i]] <- group_data
  }
  
  # Combine all group data back together
  if (length(group_data_list) > 0) {
    result_data <- bind_rows(group_data_list)
  } else {
    message("No groups were processed. Returning original data.")
    return(data)
  }
  
  # Output summary of weeks removed by group
  message("\n===== WEEKS REMOVED BY GROUP =====")
  all_weeks_removed <- sort(unique(unlist(weeks_removed_by_group)))
  
  # First report weeks removed from all groups
  if(length(all_weeks_removed) > 0) {
    all_groups_weeks <- all_weeks_removed[sapply(all_weeks_removed, function(week) {
      all(sapply(weeks_removed_by_group, function(group_weeks) week %in% group_weeks))
    })]
    
    if(length(all_groups_weeks) > 0) {
      message("Weeks removed from ALL groups: ", 
              paste(sprintf("%02d", all_groups_weeks), collapse = ", "))
    }
    
    # Then report group-specific removals
    for(group in names(weeks_removed_by_group)) {
      group_specific <- setdiff(weeks_removed_by_group[[group]], all_groups_weeks)
      if(length(group_specific) > 0) {
        message("Weeks removed from group [", group, "]: ", 
                paste(sprintf("%02d", group_specific), collapse = ", "))
      }
    }
  } else {
    message("No weeks were removed from any group.")
  }
  
  # Output summary of renamings if any occurred
  if(nrow(all_renamings) > 0) {
    message("\n===== COLUMN RENAMINGS =====")
    
    # Group renamings by pattern for cleaner output
    renaming_patterns <- all_renamings %>%
      group_by(group) %>%
      summarise(
        old_patterns = paste(gsub("^.*week_", "week_", old_var), collapse = ", "),
        new_patterns = paste(gsub("^.*week_", "week_", new_var), collapse = ", ")
      )
    
    for(i in 1:nrow(renaming_patterns)) {
      message("Group [", renaming_patterns$group[i], "]:")
      message("  ", renaming_patterns$old_patterns[i], " -> ", renaming_patterns$new_patterns[i])
    }
  } else {
    message("\nNo column renamings were needed.")
  }
  
  return(result_data)
}

# Reorganize the week variables in the dataset
enrollments_filtered_weeks_fix <- reorganize_week_variables(enrollments_filtered)

# Show basic data dimensions
cat("Loaded dataset dimensions:", dim(enrollments_filtered_weeks_fix), "\n")
```

## Identificeren van programma's en niveaus

We identificeren de beschikbare opleidingsprogramma's en onderwijsniveaus voor modellering.

```{r}
#| label: identify-programs-levels

# Get model settings from config
model_settings <- config::get("model_settings")
test_run <- model_settings$test_run
min_samples <- model_settings$min_training_samples
test_cohort_year <- model_settings$test_cohort_year

# Get unique programs and their counts, filtering for model-eligible cohort years
programs_level_count <- enrollments_filtered_weeks_fix |>
  filter(COHORT_startjaar %in% c(model_settings$training_cohort_years, test_cohort_year)) |>
  count(OPLEIDING_naam_kort, VERBINTENIS_niveau, COHORT_startjaar) |>
  pivot_wider(
    names_from = COHORT_startjaar,
    values_from = n,
    values_fill = 0
  ) |>
  rowwise() |>
  mutate(
    total_training = sum(c_across(as.character(model_settings$training_cohort_years))),
    total_test = !!as.name(as.character(test_cohort_year)),
    total = total_training + total_test
  ) |>
  ungroup() |>
  arrange(desc(total))

# Display available programs and their counts
cat("Available programs and levels by cohort year:\n")
print(programs_level_count |> arrange(desc(total)))

# Select programs based on config settings
if (test_run) {
  cat("\nRunning in TEST mode with limited programs and levels\n")
  
  # Use only the configured test programs and levels
  selected_programs <- model_settings$test_programs
  selected_levels <- model_settings$test_levels
  
  cat("Selected test programs:", paste(selected_programs, collapse=", "), "\n")
  cat("Selected test levels:", paste(selected_levels, collapse=", "), "\n")
} else {
  # In full mode, select programs with sufficient data
  filtered_programs <- programs_level_count |>
    filter(
      total_training >= model_settings$min_training_samples,
      total_test >= model_settings$min_test_samples
    )
  
  selected_programs <- unique(filtered_programs$OPLEIDING_naam_kort)
  selected_levels <- unique(filtered_programs$VERBINTENIS_niveau)
  
  cat("\nSelected", length(selected_programs), "programs with sufficient data:\n")
  print(filtered_programs |> select(OPLEIDING_naam_kort, VERBINTENIS_niveau, total_training, total_test, total))
}

# Save selected programs and levels for use in other QMD files
saveRDS(
  list(
    programs = selected_programs,
    levels = selected_levels,
    test_run = test_run,
    test_cohort_year = test_cohort_year
  ),
  file.path(config::get("modelled_dir"), "selected_programs_levels.rds")
)
```

## Gegevensvoorbereiding voor alle programma's

We bereiden eerst een dataset voor die alle programma's en niveaus bevat.

```{r}
#| label: prepare-all-data

# Define the week variable strategies to test
week_strategies <- c("none", "early", "all")

# Prepare data for all programs and levels with different week variable strategies
all_data_preps <- list()

for(week_strategy in week_strategies) {
  cat("\n--- Preparing all programs data with week strategy:", week_strategy, "---\n")
  
  all_data_preps[[week_strategy]] <- prepare_model_data(
    data = enrollments_filtered_weeks_fix,
    program_filter = NULL,
    level_filter = NULL,
    test_cohort = test_cohort_year,
    week_vars = week_strategy,
    save = TRUE
  )
  
  # Display information about the prepared data
  cat("All programs (", week_strategy, "weeks) - Training data dimensions:", 
      dim(all_data_preps[[week_strategy]]$train), "\n")
  cat("All programs (", week_strategy, "weeks) - Test data dimensions:", 
      dim(all_data_preps[[week_strategy]]$test), "\n")
  
  # Display variable counts for different strategies
  cat("Number of variables:", ncol(all_data_preps[[week_strategy]]$train), "\n")
  
  # Count week variables
  week_var_count <- sum(grepl("week", names(all_data_preps[[week_strategy]]$train)))
  cat("Number of week variables:", week_var_count, "\n")
  
  # Check class balance in training data
  train_balance <- table(all_data_preps[[week_strategy]]$train$DEELNEMER_BC_uitval)
  cat("Class balance in training data:\n")
  print(prop.table(train_balance))
}

# Show a comparison of variable counts across strategies
var_counts <- data.frame(
  strategy = week_strategies,
  total_vars = sapply(all_data_preps, function(x) ncol(x$train)),
  week_vars = sapply(all_data_preps, function(x) sum(grepl("week", names(x$train))))
)

cat("\nVariable count comparison across week strategies:\n")
print(var_counts)
```

## Gegevensvoorbereiding per programma en niveau

Nu gaan we afzonderlijke datasets voorbereiden voor elke geselecteerde programma-niveaucombinatie.

```{r}
#| label: prepare-by-program-level

# TODO: All combinations of programs - levels are checked and tried, while we now that many 
# combinations don't exist at all.

# Initialize a list to store all prepared datasets
program_level_data <- list()

# Prepare data for each program-level combination with different week variable strategies
for (program in selected_programs) {
  for (level in selected_levels) {
    # Create base identifier for this combination
    base_combo_id <- paste0(program, "_level", level)
    
    cat("\n===== Preparing data for:", base_combo_id, "=====\n")
    
    # Apply each week variable strategy
    for (week_strategy in week_strategies) {
      # Create full identifier including week strategy
      combo_id <- paste0(base_combo_id, "_weeks_", week_strategy)
      
      # Try to prepare data for this combination
      tryCatch({
        program_level_data[[combo_id]] <- prepare_model_data(
          data = enrollments_filtered_weeks_fix,
          program_filter = program,
          level_filter = level,
          test_cohort = test_cohort_year,
          week_vars = week_strategy,
          save = TRUE
        )
        
        # Display information about the prepared data
        cat("  Training data dimensions:", dim(program_level_data[[combo_id]]$train), "\n")
        cat("  Test data dimensions:", dim(program_level_data[[combo_id]]$test), "\n")
        
        # Count week variables
        week_var_count <- sum(grepl("week", names(program_level_data[[combo_id]]$train)))
        cat("  Number of week variables:", week_var_count, "\n")
        
        # Check class balance
        if (nrow(program_level_data[[combo_id]]$train) > 0) {
          train_balance <- table(program_level_data[[combo_id]]$train$DEELNEMER_BC_uitval)
          cat("  Class balance in training data:", paste(names(train_balance), "=", train_balance, collapse=", "), "\n")
          
          # Check if it meets minimum requirements
          min_class <- min(train_balance)
          if (min_class < model_settings$min_minority_class) {
            cat("  WARNING: Minority class has only", min_class, "samples (minimum needed:", 
                model_settings$min_minority_class, ")\n")
          }
        }
        
      }, error = function(e) {
        cat("  Error preparing data:", e$message, "\n")
      })
    }
  }
}

# Count how many valid datasets we created per week strategy
valid_datasets_by_strategy <- numeric(length(week_strategies))
names(valid_datasets_by_strategy) <- week_strategies

for (i in seq_along(week_strategies)) {
  strategy <- week_strategies[i]
  pattern <- paste0("_weeks_", strategy, "$")
  relevant_keys <- grep(pattern, names(program_level_data), value = TRUE)
  
  # Count how many datasets are valid for this strategy
  valid_count <- 0
  if (length(relevant_keys) > 0) {
    for (key in relevant_keys) {
      x <- program_level_data[[key]]
      if (!is.null(x) && nrow(x$train) > 0 && nrow(x$test) > 0) {
        valid_count <- valid_count + 1
      }
    }
  }
  
  valid_datasets_by_strategy[i] <- valid_count
}

cat("\n===== Summary of prepared datasets =====\n")
for (i in seq_along(week_strategies)) {
  cat("Week keuze '", week_strategies[i], "': ", valid_datasets_by_strategy[i], 
      " valid program-level datasets\n", sep="")
}

total_valid <- sum(valid_datasets_by_strategy)
cat("\nSuccessfully prepared", total_valid, "valid program-level datasets in total\n")
```

## Dataset lijst opslaan voor de volgende stappen

```{r}
#| label: save-dataset-list

# Create a summary of all prepared datasets
dataset_summary <- data.frame(
  id = names(program_level_data),
  program_level = sapply(strsplit(names(program_level_data), "_weeks_"), function(x) x[1]),
  week_strategy = sapply(strsplit(names(program_level_data), "_weeks_"), function(x) x[2]),
  train_rows = sapply(program_level_data, function(x) if(!is.null(x)) nrow(x$train) else 0),
  test_rows = sapply(program_level_data, function(x) if(!is.null(x)) nrow(x$test) else 0),
  train_columns = sapply(program_level_data, function(x) if(!is.null(x)) ncol(x$train) else 0),
  week_vars = sapply(program_level_data, function(x) {
    if(!is.null(x)) sum(grepl("week", names(x$train))) else 0
  }),
  ratio_0 = sapply(program_level_data, function(x) {
    if(!is.null(x) && nrow(x$train) > 0) {
      table_values <- table(x$train$DEELNEMER_BC_uitval)
      names_values <- names(table_values)
      if(length(names_values) >= 2) {
        table_values[names_values[1]] / sum(table_values)
      } else {
        NA
      }
    } else {
      NA
    }
  }),
  ratio_1 = sapply(program_level_data, function(x) {
    if(!is.null(x) && nrow(x$train) > 0) {
      table_values <- table(x$train$DEELNEMER_BC_uitval)
      names_values <- names(table_values)
      if(length(names_values) >= 2) {
        table_values[names_values[2]] / sum(table_values)
      } else {
        NA
      }
    } else {
      NA
    }
  })
)

# Add min_class column
dataset_summary$min_class_count <- pmin(
  dataset_summary$ratio_0 * dataset_summary$train_rows,
  dataset_summary$ratio_1 * dataset_summary$train_rows,
  na.rm = TRUE
)

# Filter for valid datasets (meeting minimum requirements)
valid_datasets <- dataset_summary |>
  filter(
    train_rows >= model_settings$min_training_samples,
    test_rows >= model_settings$min_test_samples,
    min_class_count >= model_settings$min_minority_class
  )

# Save the summary
saveRDS(dataset_summary, file.path(config::get("modelled_dir"), "prepared", "dataset_summary.rds"))
saveRDS(valid_datasets, file.path(config::get("modelled_dir"), "prepared", "valid_datasets.rds"))

# Show the summary by week strategy
dataset_summary_by_strategy <- dataset_summary |>
  group_by(week_strategy) |>
  summarize(
    total_datasets = n(),
    valid_datasets = sum(train_rows >= model_settings$min_training_samples & 
                        test_rows >= model_settings$min_test_samples &
                        min_class_count >= model_settings$min_minority_class),
    avg_train_rows = mean(train_rows),
    avg_columns = mean(train_columns),
    avg_week_vars = mean(week_vars)
  )

cat("\nDataset summary by week strategy:\n")
print(knitr::kable(dataset_summary_by_strategy, digits = 1))

# Show detailed table of valid datasets
cat("\nValid datasets meeting minimum requirements:\n")
valid_summary <- valid_datasets |>
  select(program_level, train_rows, test_rows, week_vars, min_class_count) |>
  arrange(program_level, week_strategy)

print(knitr::kable(valid_summary, digits = 0, row.names = FALSE))
```

## Verkenning

```{r}
#| label: exploration

# Get all valid program-level datasets
valid_program_files <- valid_datasets |>
  filter(week_strategy == "all") |>  # Use 'all' week strategy for most comprehensive data
  mutate(
    filename = paste0(program_level, "_weeks_all_cohort", test_cohort_year, ".rds")
  ) |>
  pull(filename)

# If no valid programs are found, just use a default example program
if (length(valid_program_files) == 0) {
  valid_program_files <- c("Dienstverlening (25498)_level2_weeks_all_cohort2023.rds")
}

# Process the first program file to display an example
# and save it for use in the correlation example
example_program <- valid_program_files[1]
processed_data <- process_program_file(example_program)

# Display the summary table from the example program
print(processed_data$summary_table)

# Process all other program files (if more than one)
if (length(valid_program_files) > 1) {
  for (i in 2:min(5, length(valid_program_files))) {  # Limit to 5 to avoid excessive processing
    process_program_file(valid_program_files[i])
  }
  
  if (length(valid_program_files) > 5) {
    cat("\nProcessed 5 out of", length(valid_program_files), "program files. Skipping the rest for brevity.\n")
  }
}

# Continue working with the example program for the correlation section
df_predictors <- processed_data$df_predictors
df_predictors_friendly <- processed_data$df_predictors_friendly
program_level <- processed_data$program_level
```

## Correlaties met retentie

Laten we analyseren welke studentkenmerken het sterkst correleren met retentie. Hiervoor gebruiken we de correlatiefuncties uit het pakket.

```{r}
#| label: correlations-with-retention

# Function to create and save correlation analysis for a program
analyze_correlations <- function(df_predictors, program_level) {
  df_correlation <- df_predictors |>
    mutate(
      # Ensure categorical variables are converted properly for correlation
      DEELNEMER_postcode4_apcg = case_when(
        DEELNEMER_postcode4_apcg == "Ja" ~ 1,
        DEELNEMER_postcode4_apcg == "Nee" ~ 0,
        .default = NA_integer_)
    )
  
  # Select all categorical variables for encoding
  categorical_data <- df_correlation |>
    select(where(is.character) | where(is.factor))
  
  # Skip problematic variables if needed
  if ("DEELNEMER_vooropleiding_categorie" %in% names(categorical_data)) {
    categorical_data <- categorical_data |> select(-DEELNEMER_vooropleiding_categorie)
  }
  
  # Create dummy variables from categorical data
  if (ncol(categorical_data) > 0) {
    # Use model.matrix for efficient one-hot encoding
    formula_text <- paste("~ +", paste(colnames(categorical_data), collapse = " + "))
    dummy_encoded <- as.data.frame(model.matrix(as.formula(formula_text), data = categorical_data))
  } else {
    dummy_encoded <- data.frame()
  }
  
  # Combine numeric variables with dummy variables
  correlation_data <- df_correlation |>
    select(where(is.numeric)) |>
    bind_cols(dummy_encoded) |>
    select_cols_for_correlation(na_thresh = 0.8)
  
  # Calculate correlations with retention
  retention_correlations <- correlate_teams_and_filter(
    correlation_data,
    target_var = "Retentie",
    filter_type = "outside",
    correlation_limits = c(-0.15, 0.15),
    # Exclude terms directly related to the outcome to avoid tautological correlations
    exclude_terms = c("DEELNEMER_BC_uitval", "Retentie")
  )
  
  # Format program name for display
  program_name_display <- str_replace(program_level, "_level", " - Niveau ")
  
  # Plot the correlations
  retention_correlation_plot <- plot_teams_correlations(
    retention_correlations,
    target_var = "Retentie",
    title_text = paste0("Kenmerken met sterkste relatie tot retentie - ", program_name_display)
  )
  
  # Save the correlation results as RDS
  saveRDS(
    retention_correlations,
    file.path(config::get("modelled_dir"), "prepared", paste0(program_level, "_correlations.rds"))
  )
  
  # Save the correlation plot as PNG
  ggsave(
    file.path(config::get("modelled_dir"), "prepared", paste0(program_level, "_correlations_plot.png")),
    retention_correlation_plot,
    width = 12,
    height = 8
  )
  
  return(list(
    correlations = retention_correlations,
    plot = retention_correlation_plot
  ))
}

# Run correlation analysis for the example program
correlation_results <- analyze_correlations(df_predictors, program_level)

# Display the plot
print(correlation_results$plot)

# If we have valid_program_files data, we can process all programs
# But we're reusing the function for each program vs creating a new loop
# to avoid duplicating too much code

```

In de bovenstaande grafiek zien we welke studentkenmerken het sterkst correleren met de retentie van studenten. Deze inzichten kunnen gebruikt worden om:

1. De belangrijkste factoren voor het voorspellen van uitval te identificeren
2. Inzicht te krijgen in welke interventies mogelijk het meest effectief kunnen zijn
3. De interpretatie van het predictieve model te ondersteunen

## Volgende stappen

De voorbereide datasets zijn nu beschikbaar in de map `data/modelled/prepared` en klaar voor modeltraining. Het volgende document in deze workflow zal voorspellende modellen trainen met behulp van deze voorbereide datasets. De samenvattingstabel en correlaties zijn ook opgeslagen voor later gebruik.
